{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade lightgbm\n",
    "# !pip install pycodestyle flake8 pycodestyle_magic\n",
    "# !conda install py-xgboost\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I did was to read the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data = pd.read_csv('../data_root/raw/wine_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My analysis will be done based on five aspects:\n",
    "\n",
    "1. Exploratory Data Analysis (EDA)\n",
    "2. Data Visualization\n",
    "3. Feature Engineering\n",
    "4. Model Building and Evaluation\n",
    "5. Results and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a first look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the sample of our data above. We note that our data is mostly text, contains quite a number of missing values, has only 2 numeric columns and we are to predict one of them (points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are usually two kinds of bad data: duplicate and misssing.\n",
    "I decided to check for duplicate data and delete them if they exist.\n",
    "My assumption: If the data contains the same name, title and description, then it is the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "print(\"The total number of data samples: \", data.shape[0])\n",
    "print(\"Duplicate data \", data[data.duplicated([\n",
    "    'taster_name', 'title', 'description']\n",
    ")].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that there are 58 duplicate samples in our dataset so we have to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data = data.drop_duplicates(['taster_name', 'title', 'description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would need to take care of missing data, let's first check how many they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a lot of missing data and we are going to have to take care of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "# if there are any infinity values in the data,\n",
    "# replace with NaN\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['points'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all wine points are between 80 - 100 and most wine points are 88. Now lets see how price affects the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "g = sns.regplot(x='points', y='price', data=data, fit_reg=True)\n",
    "g.set_title(\"Points x Price Distribuition\", fontsize=20)\n",
    "g.set_xlabel(\"Points\", fontsize=15)\n",
    "g.set_ylabel(\"Price\", fontsize=15)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, the higher the price, the higher the probability of getting a high point is, and this seems quite logical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see how country affects price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['price', 'points', 'country', 'province']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have to be careful while generating the features in order to avoid data leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:1: E302 expected 2 blank lines, found 1\n",
      "16:1: E302 expected 2 blank lines, found 1\n",
      "24:80: E501 line too long (81 > 79 characters)\n",
      "26:80: E501 line too long (84 > 79 characters)\n",
      "28:80: E501 line too long (86 > 79 characters)\n",
      "30:80: E501 line too long (84 > 79 characters)\n",
      "31:80: E501 line too long (80 > 79 characters)\n",
      "32:80: E501 line too long (88 > 79 characters)\n",
      "33:1: W293 blank line contains whitespace\n",
      "41:80: E501 line too long (85 > 79 characters)\n",
      "42:80: E501 line too long (81 > 79 characters)\n",
      "43:80: E501 line too long (89 > 79 characters)\n",
      "45:80: E501 line too long (87 > 79 characters)\n",
      "46:80: E501 line too long (82 > 79 characters)\n",
      "47:80: E501 line too long (91 > 79 characters)\n",
      "49:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "def handle_missing_values(data):\n",
    "    data = data.fillna(data.mean())  # fill missing values with the mean\n",
    "    # the rows which have country and province empty\n",
    "    # can be done away with since they are only 6\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_trans(df, place, obj, stat):\n",
    "    return df.groupby(place)[obj].transform(stat)\n",
    "\n",
    "\n",
    "def data_diff(df, col1, col2):\n",
    "    return df[col1] - df[col2]\n",
    "\n",
    "\n",
    "def generate_price_features(df):\n",
    "    country_group = df.groupby('country')\n",
    "    province_group = df.groupby('province')\n",
    "#     df['price_per_country_mean'] = country_group['price'].transform('mean')\n",
    "    df['price_per_country_mean'] = data_trans(\n",
    "                                    df, 'country', 'price', 'mean'\n",
    "                                    )\n",
    "    df['price_per_country_mean_diff'] = data_diff(\n",
    "                                            df, 'price', 'price_per_country_mean'\n",
    "                                        )\n",
    "#     df['price_per_country_mean_diff'] = df['price'] - df['price_per_country_mean']\n",
    "    df['price_per_country_median'] = country_group['price'].transform('median')\n",
    "    df['price_per_country_median_diff'] = df['price'] - df['price_per_country_median']\n",
    "    df['price_per_province_mean'] = province_group['price'].transform('mean')\n",
    "    df['price_per_province_mean_diff'] = df['price'] - df['price_per_province_mean']\n",
    "    df['price_per_province_median'] = country_group['price'].transform('median')\n",
    "    df['price_per_province_median_diff'] = df['price'] - df['price_per_province_median']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_point_features(df):\n",
    "    country_group = df.groupby('country')\n",
    "    province_group = df.groupby('province')\n",
    "    df['points_per_country_mean'] = country_group['points'].transform('mean')\n",
    "    df['points_per_country_mean_diff'] = df['points'] - df['points_per_country_mean']\n",
    "    df['points_per_country_median'] = country_group['points'].transform('median')\n",
    "    df['points_per_country_median_diff'] = df['points'] - df['points_per_country_median']\n",
    "    df['points_per_province_mean'] = province_group['points'].transform('mean')\n",
    "    df['points_per_province_mean_diff'] = df['points'] - df['points_per_province_mean']\n",
    "    df['points_per_province_median'] = country_group['points'].transform('median')\n",
    "    df['points_per_province_median_diff'] = df['points'] - df['points_per_province_median']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data = handle_missing_values(data)\n",
    "data = generate_price_features(data)\n",
    "data = generate_point_features(data)\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model to select the most important features; It is not the main model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "train_features = [\n",
    "    'price',\n",
    "    'price_per_country_mean',\n",
    "    'price_per_country_mean_diff',\n",
    "    'price_per_country_median',\n",
    "    'price_per_country_median_diff',\n",
    "    'price_per_province_mean',\n",
    "    'price_per_province_mean_diff',\n",
    "    'price_per_province_median',\n",
    "    'price_per_province_median_diff',\n",
    "    'points_per_country_mean',\n",
    "    'points_per_country_median',\n",
    "    'points_per_province_mean',\n",
    "    'points_per_province_median',\n",
    "]\n",
    "\n",
    "target_feature = 'points'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "df_train = data[train_features].copy().values\n",
    "target = data[target_feature].copy().values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first build an xgb model for the dataset and test it on validation part using KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_, X_valid = X_train[train_index], X_train[test_index]\n",
    "    y_, y_valid = y_train[train_index], y_train[test_index]\n",
    "    sc = StandardScaler()\n",
    "    X_ = sc.fit_transform(X_)\n",
    "    X_valid = sc.transform(X_valid)\n",
    "    std_mean = sc.mean_ \n",
    "    std_var = sc.var_\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "                    n_estimators=1000,\n",
    "                    max_depth=20,\n",
    "                    importance_type=\"gain\",\n",
    "                    learning_rate=0.01,\n",
    "                    n_jobs=4\n",
    "                )\n",
    "    xgb_model.fit(X_, y_,\n",
    "                  early_stopping_rounds=5,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  eval_metric=\"rmse\",\n",
    "                  verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the model to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)\n",
    "print('saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "we first read the model file then begin evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle_model.pkl\", 'rb') as file:\n",
    "    recovered_lgb_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the values of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = (X_test - std_mean) / (std_var ** 0.5)\n",
    "predictions = recovered_lgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ = mse(predictions, y_test)\n",
    "print(error_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our mean square error gives us an error of 11.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for feature importance to know which parameters were very important in creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = xgb_model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=feature_importance, y=train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that important features that are used to generate the predictions so we select them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "    'price',\n",
    "    'price_per_country_mean',\n",
    "    'price_per_country_mean_diff',\n",
    "    'price_per_country_median',\n",
    "    'price_per_country_median_diff',\n",
    "    'price_per_province_mean',\n",
    "    'price_per_province_mean_diff',\n",
    "    'points_per_country_mean',\n",
    "    'points_per_country_median',\n",
    "    'points_per_province_mean'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we would save these features to ensure persistence\n",
    "so for every new data we get, we would use these features to generate the features**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
